{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HYPER PARAMETER TUNING\n",
    "\n",
    "Last step, we selected xgboost as our best performance model for loan default prediction, this step we will do \n",
    "hyperparameter tuning, which is the process of finding the best combination of hyperparameters for a xgboost to achieve optimal performance \n",
    "\n",
    "xgboost \n",
    "\n",
    "**Best model parameters**: {'xgb__colsample_bytree': 1.0, 'xgb__eta': 0.3, 'xgb__max_depth': 9, 'xgb__n_estimators': 200} \n",
    "\n",
    "**Best model score**:  0.9012065393763203\n",
    "\n",
    "\n",
    "**private score** 0.82431 \n",
    "**public score** 0.81435\n",
    "\n",
    "\n",
    "random forest \n",
    "\n",
    "**Best model parameters**: {'criterion': 'entropy', 'max_depth': None, 'n_estimators': 200}\n",
    "\n",
    "**Best model score**:  0.904551\n",
    "\n",
    "**private score** 0.82739\n",
    "**public score** 0.82715"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-08T01:47:47.456987Z",
     "iopub.status.idle": "2023-05-08T01:47:47.457544Z"
    }
   },
   "outputs": [],
   "source": [
    "# Main tools we used:\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from scipy.stats import uniform\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import  make_scorer,accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve\n",
    "\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "## last step, we found best performance dataset is processed dataset for xgboost\n",
    "df_train_processed = pd.read_csv(\"processed_data_train.csv\")\n",
    "df_test_processed = pd.read_csv(\"processed_data_test.csv\")\n",
    "\n",
    "df_test= pd.read_csv(\"cs-test.csv\")\n",
    "df_train_oversampled = pd.read_csv(\"oversampled_data.csv\")\n",
    "\n",
    "## try to create new cols on top of oversampled data\n",
    "# Create a new column 'TotalPastDue' by summing the values of the three columns\n",
    "df_train_oversampled['TotalPastDue'] = df_train_oversampled['NumberOfTime30-59DaysPastDueNotWorse'] + df_train_oversampled['NumberOfTimes90DaysLate'] + df_train_oversampled['NumberOfTime60-89DaysPastDueNotWorse']\n",
    "\n",
    "# Drop the individual columns if desired\n",
    "df_train_oversampled = df_train_oversampled.drop(['NumberOfTime30-59DaysPastDueNotWorse', 'NumberOfTimes90DaysLate', 'NumberOfTime60-89DaysPastDueNotWorse'], axis=1)\n",
    "\n",
    "# Create test dataset for new created cols\n",
    "df_test_processed_created = df_test_processed.copy()\n",
    "df_test_processed_created['TotalPastDue'] = df_test_processed_created['NumberOfTime30-59DaysPastDueNotWorse'] + df_test_processed_created['NumberOfTimes90DaysLate'] + df_test_processed_created['NumberOfTime60-89DaysPastDueNotWorse']\n",
    "df_test_processed_created = df_test_processed_created.drop(['NumberOfTime30-59DaysPastDueNotWorse', 'NumberOfTimes90DaysLate', 'NumberOfTime60-89DaysPastDueNotWorse'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(X_train, Y_train, test_size=0.3, random_state=2020):\n",
    "    \"\"\"\n",
    "    Split the data into training and validation sets.\n",
    "    \n",
    "    Parameters:\n",
    "    - X_train: The features (input variables) for training.\n",
    "    - Y_train: The target variable for training.\n",
    "    - test_size: The proportion of the data to include in the validation set. Default is 0.3.\n",
    "    - random_state: The random state for reproducibility. Default is 2020.\n",
    "    \n",
    "    Returns:\n",
    "    - X_train: The training features.\n",
    "    - val_x: The validation features.\n",
    "    - Y_train: The training target variable.\n",
    "    - val_y: The validation target variable.\n",
    "    \"\"\"\n",
    "    X_train, val_x, Y_train, val_y = train_test_split(\n",
    "        X_train, Y_train, test_size=test_size, random_state=random_state)\n",
    "    \n",
    "    return X_train, val_x, Y_train, val_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_train, Y_train, val_x, val_y):\n",
    "    # Extract the model name from the model object\n",
    "    model_name = type(model).__name__\n",
    "    \n",
    "    if '-' in model_name:\n",
    "        model_name = model_name.split('-')[1]\n",
    "\n",
    "    # Calculate the accuracy score on the training set\n",
    "    accuracy_train = accuracy_score(Y_train, model.predict(X_train))\n",
    "    print(\"Accuracy on training set:\", accuracy_train)\n",
    "\n",
    "    # Calculate the ROC AUC score on the training set\n",
    "    roc_auc_train = roc_auc_score(Y_train, model.predict_proba(X_train)[:, 1])\n",
    "    print(\"ROC AUC score on training set:\", roc_auc_train)\n",
    "\n",
    "    # Calculate the accuracy score on the validation set\n",
    "    accuracy_val = accuracy_score(val_y, model.predict(val_x))\n",
    "    print(\"Accuracy on validation set:\", accuracy_val)\n",
    "\n",
    "    # Calculate the ROC AUC score on the validation set\n",
    "    roc_auc_val = roc_auc_score(val_y, model.predict_proba(val_x)[:, 1])\n",
    "    print(\"ROC AUC score on validation set:\", roc_auc_val)\n",
    "\n",
    "    # Compute the false positive rate, true positive rate, and thresholds for training set\n",
    "    fpr_train, tpr_train, thresholds_train = roc_curve(Y_train, model.predict_proba(X_train)[:, 1])\n",
    "\n",
    "    # Compute the false positive rate, true positive rate, and thresholds for validation set\n",
    "    fpr_val, tpr_val, thresholds_val = roc_curve(val_y, model.predict_proba(val_x)[:, 1])\n",
    "\n",
    "    # Plot the ROC curves\n",
    "    plt.plot(fpr_train, tpr_train, label='Training')\n",
    "    plt.plot(fpr_val, tpr_val, label='Validation')\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', label='Default')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve ({})'.format(model_name))\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_evaluation_metrics(model, val_x, val_y):\n",
    "    \"\"\"\n",
    "    Calculates and displays the evaluation metrics for a classification model.\n",
    "\n",
    "    Parameters:\n",
    "    - model: Trained classification model\n",
    "    - val_x: Validation set features\n",
    "    - val_y: Validation set target variable\n",
    "\n",
    "    Prints a table showing the evaluation metrics: Accuracy, Precision, Recall, F1-score, AUC-ROC, and Gini coefficient.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Make predictions on the validation set\n",
    "    y_pred = model.predict(val_x)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(val_y, y_pred)\n",
    "\n",
    "    # Calculate precision\n",
    "    precision = precision_score(val_y, y_pred)\n",
    "\n",
    "    # Calculate recall\n",
    "    recall = recall_score(val_y, y_pred)\n",
    "\n",
    "    # Calculate F1-score\n",
    "    f1 = f1_score(val_y, y_pred)\n",
    "\n",
    "    # Calculate predicted probabilities for positive class\n",
    "    y_pred_prob = model.predict_proba(val_x)[:, 1]\n",
    "\n",
    "    # Calculate AUC-ROC\n",
    "    auc_roc = roc_auc_score(val_y, y_pred_prob)\n",
    "\n",
    "    # Calculate Gini coefficient\n",
    "    gini = 2 * auc_roc - 1\n",
    "\n",
    "    # Create a list of metric names and values\n",
    "    metric_names = ['Accuracy', 'Precision', 'Recall', 'F1-score', 'AUC-ROC', 'Gini coefficient']\n",
    "    metric_values = [accuracy, precision, recall, f1, auc_roc, gini]\n",
    "\n",
    "    # Create a list of metric rows\n",
    "    metric_rows = [[name, value] for name, value in zip(metric_names, metric_values)]\n",
    "\n",
    "    # Print the table for evaluation metrics\n",
    "    print(tabulate(metric_rows, headers=['Metric', 'Value'], tablefmt='orgtbl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-08T01:47:47.458379Z",
     "iopub.status.idle": "2023-05-08T01:47:47.458975Z"
    }
   },
   "outputs": [],
   "source": [
    "## split df_train_processed data\n",
    "## X_train, val_x, Y_train, val_y = split_data(df_train_processed.drop('SeriousDlqin2yrs', axis=1), df_train_processed['SeriousDlqin2yrs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "## split oversampled data\n",
    "X_train, val_x, Y_train, val_y = split_data(df_train_oversampled.drop('SeriousDlqin2yrs', axis=1), df_train_oversampled['SeriousDlqin2yrs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RevolvingUtilizationOfUnsecuredLines</th>\n",
       "      <th>age</th>\n",
       "      <th>DebtRatio</th>\n",
       "      <th>MonthlyIncome</th>\n",
       "      <th>NumberOfOpenCreditLinesAndLoans</th>\n",
       "      <th>NumberRealEstateLoansOrLines</th>\n",
       "      <th>NumberOfDependents</th>\n",
       "      <th>TotalPastDue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>69651</th>\n",
       "      <td>0.057140</td>\n",
       "      <td>26</td>\n",
       "      <td>550.000000</td>\n",
       "      <td>5400.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176886</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>32</td>\n",
       "      <td>0.131231</td>\n",
       "      <td>1249.118071</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.763858</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104414</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>28</td>\n",
       "      <td>0.092987</td>\n",
       "      <td>5118.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7720</th>\n",
       "      <td>0.506165</td>\n",
       "      <td>23</td>\n",
       "      <td>0.019026</td>\n",
       "      <td>3100.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115695</th>\n",
       "      <td>0.116326</td>\n",
       "      <td>49</td>\n",
       "      <td>0.462667</td>\n",
       "      <td>6200.000000</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151709</th>\n",
       "      <td>1.044848</td>\n",
       "      <td>50</td>\n",
       "      <td>0.432649</td>\n",
       "      <td>15000.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96184</th>\n",
       "      <td>0.896048</td>\n",
       "      <td>33</td>\n",
       "      <td>0.644385</td>\n",
       "      <td>2617.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20039</th>\n",
       "      <td>0.012690</td>\n",
       "      <td>54</td>\n",
       "      <td>0.219867</td>\n",
       "      <td>6180.000000</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18523</th>\n",
       "      <td>0.344479</td>\n",
       "      <td>63</td>\n",
       "      <td>0.165955</td>\n",
       "      <td>28350.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192904</th>\n",
       "      <td>0.728311</td>\n",
       "      <td>33</td>\n",
       "      <td>0.178457</td>\n",
       "      <td>2613.231381</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>190752 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        RevolvingUtilizationOfUnsecuredLines  age   DebtRatio  MonthlyIncome  \\\n",
       "69651                               0.057140   26  550.000000    5400.000000   \n",
       "176886                              1.000000   32    0.131231    1249.118071   \n",
       "104414                              1.000000   28    0.092987    5118.000000   \n",
       "7720                                0.506165   23    0.019026    3100.000000   \n",
       "115695                              0.116326   49    0.462667    6200.000000   \n",
       "...                                      ...  ...         ...            ...   \n",
       "151709                              1.044848   50    0.432649   15000.000000   \n",
       "96184                               0.896048   33    0.644385    2617.000000   \n",
       "20039                               0.012690   54    0.219867    6180.000000   \n",
       "18523                               0.344479   63    0.165955   28350.000000   \n",
       "192904                              0.728311   33    0.178457    2613.231381   \n",
       "\n",
       "        NumberOfOpenCreditLinesAndLoans  NumberRealEstateLoansOrLines  \\\n",
       "69651                                 3                             0   \n",
       "176886                                1                             0   \n",
       "104414                                4                             0   \n",
       "7720                                  4                             0   \n",
       "115695                               15                             2   \n",
       "...                                 ...                           ...   \n",
       "151709                               10                             2   \n",
       "96184                                10                             1   \n",
       "20039                                17                             3   \n",
       "18523                                 4                             2   \n",
       "192904                                8                             0   \n",
       "\n",
       "        NumberOfDependents  TotalPastDue  \n",
       "69651             0.000000             0  \n",
       "176886            1.763858             1  \n",
       "104414            1.000000             0  \n",
       "7720              0.000000             0  \n",
       "115695            2.000000             1  \n",
       "...                    ...           ...  \n",
       "151709            2.000000             0  \n",
       "96184             0.000000             0  \n",
       "20039             0.000000             0  \n",
       "18523             0.000000             0  \n",
       "192904            2.000000             0  \n",
       "\n",
       "[190752 rows x 8 columns]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_cfl = xgb.XGBClassifier(n_jobs = -1)\n",
    "xgb_cfl.fit(X_train, Y_train)\n",
    "y_pred = xgb_cfl.predict(val_x)\n",
    "y_score = xgb_cfl.predict_proba(val_x)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimate: 1.001\n",
      "Fitting 3 folds for each of 54 candidates, totalling 162 fits\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "counter = Counter(Y_train)\n",
    "# estimate scale_pos_weight value to handle class imbalance during training\n",
    "estimate = counter[0] / counter[1]\n",
    "print('Estimate: %.3f' % estimate)\n",
    "#define the param grid\n",
    "# Parameters of pipelines can be set using ‘__’ separated para\n",
    "clf_grid = {\n",
    "    'xgb__eta': [0.05, 0.1, 0.3],\n",
    "    'xgb__max_depth': [3, 6, 12],\n",
    "    'xgb__colsample_bytree': [0.9, 1.0],\n",
    "    'xgb__n_estimators': [50, 100, 200]\n",
    "    }\n",
    "#define the pipeline\n",
    "model_pipe = Pipeline([\n",
    "    ('xgb', xgb.XGBClassifier(\n",
    "                              n_jobs=-1, scale_pos_weight=estimate))\n",
    "])\n",
    "#define the classifer\n",
    "clf = GridSearchCV(model_pipe,\n",
    "                   clf_grid,\n",
    "                   n_jobs=-1,\n",
    "                   cv=3, \n",
    "                   verbose=50, \n",
    "                   scoring='roc_auc')\n",
    "#fit to training data\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "# Get the best-performing model based on validation set AUC score\n",
    "best_model = clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 81 candidates, totalling 243 fits\n",
      "Accuracy: 0.9058\n",
      "Precision: 0.9151\n",
      "F1-score: 0.9049\n",
      "Best model parameters: \n",
      "\n",
      "{'xgb__colsample_bytree': 1.0, 'xgb__eta': 0.3, 'xgb__max_depth': 9, 'xgb__n_estimators': 200}\n",
      "Best model score: \n",
      "\n",
      "0.9012065393763203\n"
     ]
    }
   ],
   "source": [
    "# Define the scoring metrics\n",
    "scoring_metrics = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'precision': make_scorer(precision_score),\n",
    "    'f1': make_scorer(f1_score),\n",
    "    'roc_auc': make_scorer(roc_auc_score)\n",
    "}\n",
    "\n",
    "# Define the parameter grid\n",
    "clf_grid = {\n",
    "    'xgb__eta': [0.05, 0.1, 0.3],\n",
    "    'xgb__max_depth': [3, 6, 9],\n",
    "    'xgb__colsample_bytree': [0.8, 0.9, 1.0],\n",
    "    'xgb__n_estimators': [100, 150, 200]\n",
    "}\n",
    "\n",
    "# Define the pipeline\n",
    "model_pipe = Pipeline([\n",
    "    ('xgb', xgb.XGBClassifier(n_jobs=-1, scale_pos_weight=estimate))\n",
    "])\n",
    "\n",
    "# Define the classifier\n",
    "clf = GridSearchCV(model_pipe,\n",
    "                   clf_grid,\n",
    "                   n_jobs=-1,\n",
    "                   cv=3,\n",
    "                   verbose=50,\n",
    "                   scoring=scoring_metrics,\n",
    "                   refit='roc_auc')  # You can specify the desired metric for refitting the best model\n",
    "\n",
    "# Fit to the training data\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "# Get the best-performing model based on the specified scoring metric\n",
    "best_model = clf.best_estimator_\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_pred = best_model.predict(val_x)\n",
    "\n",
    "# Calculate the desired evaluation metrics\n",
    "accuracy = accuracy_score(val_y, y_pred)\n",
    "precision = precision_score(val_y, y_pred)\n",
    "f1 = f1_score(val_y, y_pred)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Accuracy: {:.4f}\".format(accuracy))\n",
    "print(\"Precision: {:.4f}\".format(precision))\n",
    "print(\"F1-score: {:.4f}\".format(f1))\n",
    "\n",
    "print(\"Best model parameters: \\n\")\n",
    "print(clf.best_params_ )\n",
    "print(\"Best model score: \\n\")\n",
    "print(clf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(best_model, X_train, Y_train, val_x, val_y)\n",
    "display_evaluation_metrics(best_model, val_x, val_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Metric           |    Value |\n",
      "|------------------+----------|\n",
      "| Accuracy         | 0.905825 |\n",
      "| Precision        | 0.915072 |\n",
      "| Recall           | 0.976083 |\n",
      "| F1-score         | 0.904912 |\n",
      "| AUC-ROC          | 0.969846 |\n",
      "| Gini coefficient | 0.939692 |\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "# Create a list of metric names and values\n",
    "metric_names = ['Accuracy', 'Precision', 'Recall', 'F1-score', 'AUC-ROC', 'Gini coefficient']\n",
    "metric_values = [accuracy, precision, recall, f1, auc_roc, gini]\n",
    "\n",
    "# Create a list of metric rows\n",
    "metric_rows = [[name, value] for name, value in zip(metric_names, metric_values)]\n",
    "\n",
    "# Print the table for evaluation metrics\n",
    "print(tabulate(metric_rows, headers=['Metric', 'Value'], tablefmt='orgtbl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_oversampled = df_test_processed\n",
    "# Create a new column 'TotalPastDue' by summing the values of the three columns\n",
    "df_test_oversampled['TotalPastDue'] = df_test_processed['NumberOfTime30-59DaysPastDueNotWorse'] + df_test_processed['NumberOfTimes90DaysLate'] + df_test_processed['NumberOfTime60-89DaysPastDueNotWorse']\n",
    "# Drop the individual columns if desired\n",
    "\n",
    "df_test_oversampled = df_test_processed.drop(['NumberOfTime30-59DaysPastDueNotWorse', 'NumberOfTimes90DaysLate', 'NumberOfTime60-89DaysPastDueNotWorse'], axis=1)\n",
    "\n",
    "test_X = df_test_oversampled.drop([\"SeriousDlqin2yrs\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best model from GridSearchCV\n",
    "\n",
    "## Prediction_XGB = best_model.predict(X_train)\n",
    "\n",
    "predict_prob = best_model.predict_proba(test_X)[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the best model from GridSearchCV to predit for test data\n",
    "df_test_id =df_test[\"Unnamed: 0\"]\n",
    "result = pd.DataFrame({\"Id\": df_test_id, \"Probability\": predict_prob})\n",
    "result[\"Id\"] = result[\"Id\"].astype(int)\n",
    "result[\"Probability\"] = result[\"Probability\"].astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model from GridSearchCV to predit for test data to csv\n",
    "result.to_csv('model_output/predictions-best_model_xgboost.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/best_model_XGBOOST.pkl']"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the best model for XGBoost\n",
    "joblib.dump(best_model, 'models/best_model_XGBOOST.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomizedSearchCV(xgb, param_distributions=TRAIN_CONFIGS[\"model_params\"], n_iter=400, scoring='roc_auc', n_jobs=-1, cv=StratifiedKFold(n_splits=5, shuffle = True, random_state = 0), verbose=3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-08T01:47:47.459779Z",
     "iopub.status.idle": "2023-05-08T01:47:47.460375Z"
    }
   },
   "outputs": [],
   "source": [
    "class RandomSearch(object):\n",
    "    \n",
    "    def __init__(self,X_train,y_train,model,hyperparameters):\n",
    "        \n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.model = model\n",
    "        self.hyperparameters = hyperparameters\n",
    "        \n",
    "    def RandomSearch(self):\n",
    "        # Create randomized search 10-fold cross validation and 100 iterations\n",
    "        cv = 10\n",
    "        clf = RandomizedSearchCV(self.model,\n",
    "                                 self.hyperparameters,\n",
    "                                 random_state=1,\n",
    "                                 n_iter=100,\n",
    "                                 cv=cv,\n",
    "                                 verbose=0,\n",
    "                                 n_jobs=-1,\n",
    "                                 )\n",
    "        # Fit randomized search\n",
    "        best_model = clf.fit(self.X_train, self.y_train)\n",
    "        message = (best_model.best_score_, best_model.best_params_)\n",
    "        print(\"Best: %f using %s\" % (message))\n",
    "\n",
    "        return best_model,best_model.best_params_\n",
    "    \n",
    "    def BestModelPridict(self,X_test):\n",
    "        \n",
    "        best_model,_ = self.RandomSearch()\n",
    "        pred = best_model.predict(X_test)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-08T01:47:47.461164Z",
     "iopub.status.idle": "2023-05-08T01:47:47.461670Z"
    }
   },
   "outputs": [],
   "source": [
    "class GridSearch(object):\n",
    "    \n",
    "    def __init__(self,X_train,y_train,model,hyperparameters):\n",
    "        \n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.model = model\n",
    "        self.hyperparameters = hyperparameters\n",
    "        \n",
    "    def GridSearch(self):\n",
    "        # Create randomized search 10-fold cross validation and 100 iterations\n",
    "        cv = 10\n",
    "        clf = GridSearchCV(self.model,\n",
    "                                 self.hyperparameters,\n",
    "                                 cv=cv,\n",
    "                                 verbose=0,\n",
    "                                 n_jobs=-1,\n",
    "                                 )\n",
    "        # Fit randomized search\n",
    "        best_model = clf.fit(self.X_train, self.y_train)\n",
    "        message = (best_model.best_score_, best_model.best_params_)\n",
    "        print(\"Best: %f using %s\" % (message))\n",
    "\n",
    "        return best_model,best_model.best_params_\n",
    "    \n",
    "    def BestModelPridict(self,X_test):\n",
    "        \n",
    "        best_model,_ = self.GridSearch()\n",
    "        pred = best_model.predict(X_test)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "### HYPER PARAMETER TUNING\n",
    "class RandomSearch(object):\n",
    "    \n",
    "    def __init__(self,X_train,y_train,model,hyperparameters):\n",
    "        \n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.model = model\n",
    "        self.hyperparameters = hyperparameters\n",
    "        \n",
    "    def RandomSearch(self):\n",
    "        # Create randomized search 10-fold cross validation and 100 iterations\n",
    "        cv = 10\n",
    "        clf = RandomizedSearchCV(self.model,\n",
    "                                 self.hyperparameters,\n",
    "                                 random_state=1,\n",
    "                                 n_iter=100,\n",
    "                                 cv=cv,\n",
    "                                 verbose=0,\n",
    "                                 n_jobs=-1,\n",
    "                                 )\n",
    "        # Fit randomized search\n",
    "        best_model = clf.fit(self.X_train, self.y_train)\n",
    "        message = (best_model.best_score_, best_model.best_params_)\n",
    "        print(\"Best: %f using %s\" % (message))\n",
    "\n",
    "        return best_model,best_model.best_params_\n",
    "    \n",
    "    def BestModelPridict(self,X_test):\n",
    "        \n",
    "        best_model,_ = self.RandomSearch()\n",
    "        pred = best_model.predict(X_test)\n",
    "        return pred\n",
    "\n",
    "class GridSearch(object):\n",
    "    \n",
    "    def __init__(self,X_train,y_train,model,hyperparameters):\n",
    "        \n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.model = model\n",
    "        self.hyperparameters = hyperparameters\n",
    "        \n",
    "    def GridSearch(self):\n",
    "        # Create randomized search 10-fold cross validation and 100 iterations\n",
    "        cv = 10\n",
    "        clf = GridSearchCV(self.model,\n",
    "                                 self.hyperparameters,\n",
    "                                 cv=cv,\n",
    "                                 verbose=0,\n",
    "                                 n_jobs=-1,\n",
    "                                 )\n",
    "        # Fit randomized search\n",
    "        best_model = clf.fit(self.X_train, self.y_train)\n",
    "        message = (best_model.best_score_, best_model.best_params_)\n",
    "        print(\"Best: %f using %s\" % (message))\n",
    "\n",
    "        return best_model,best_model.best_params_\n",
    "    \n",
    "    def BestModelPridict(self,X_test):\n",
    "        \n",
    "        best_model,_ = self.GridSearch()\n",
    "        pred = best_model.predict(X_test)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-08T01:47:47.473139Z",
     "iopub.status.idle": "2023-05-08T01:47:47.473588Z"
    }
   },
   "source": [
    "#### SVC Model ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-08T01:47:47.474251Z",
     "iopub.status.idle": "2023-05-08T01:47:47.474742Z"
    }
   },
   "outputs": [],
   "source": [
    "# c_values = [0.1, 0.3, 0.5, 0.7, 0.9, 1.0, 1.3, 1.5, 1.7, 2.0]\n",
    "# kernel_values = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "# param_grid = {'C': c_values, 'kernel': kernel_values}\n",
    "\n",
    "# model_SVC = SVC()\n",
    "# SVC_GridSearch = GridSearchCV(model_SVC, param_grid, scoring='f1_weighted')\n",
    "\n",
    "# SVC_GridSearch.fit(X_train, Y_train)\n",
    "# best_model = SVC_GridSearch.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-08T01:47:47.475367Z",
     "iopub.status.idle": "2023-05-08T01:47:47.475812Z"
    }
   },
   "outputs": [],
   "source": [
    "# Prediction_SVC = best_model.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-08T01:47:47.484457Z",
     "iopub.status.idle": "2023-05-08T01:47:47.485074Z"
    }
   },
   "source": [
    "#### RANDOM FOREST ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-08T01:47:47.485761Z",
     "iopub.status.idle": "2023-05-08T01:47:47.486882Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.904551 using {'criterion': 'entropy', 'max_depth': None, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "# wanted to tunning against max_features_list=['auto', 'sqrt', 'log2', None] but it’s taking such long time to train (overnight) \n",
    "n_estimators_value = [100,150,200,250,300]\n",
    "criterion_val = [\"gini\", \"entropy\"]\n",
    "max_depth_val = [5, 10, 15, None]\n",
    "# max_features_list=['auto', 'sqrt', 'log2', None]\n",
    "param_grid = dict(criterion=criterion_val, n_estimators=n_estimators_value,max_depth=max_depth_val )\n",
    "\n",
    "model_RF = RandomForestClassifier()\n",
    "RF_GridSearch = GridSearch(X_train,Y_train,model_RF,param_grid)\n",
    "\n",
    "## private score 0.8471 public score 0.8425\n",
    "best_model, best_params = RF_GridSearch.GridSearch()\n",
    "\n",
    "## Prediction_GB = GB_GridSearch.BestModelPridict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy', 'max_depth': None, 'n_estimators': 200}"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.9993446988760275\n",
      "ROC AUC score on training set: 0.9998936957956608\n",
      "Accuracy on validation set: 0.9056659164301791\n",
      "ROC AUC score on validation set: 0.9699927128510653\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluate_model(best_model, X_train, Y_train, val_x, val_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Metric           |    Value |\n",
      "|------------------+----------|\n",
      "| Accuracy         | 0.905666 |\n",
      "| Precision        | 0.903099 |\n",
      "| Recall           | 0.909144 |\n",
      "| F1-score         | 0.906112 |\n",
      "| AUC-ROC          | 0.969993 |\n",
      "| Gini coefficient | 0.939985 |\n"
     ]
    }
   ],
   "source": [
    "display_evaluation_metrics(best_model, val_x, val_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = df_test_processed_created.drop([\"SeriousDlqin2yrs\"],axis=1)\n",
    "# Use the best model for prediction\n",
    "probabilities = best_model.predict_proba(X_test)\n",
    "\n",
    "# Extract the probability of belonging to the positive class (default)\n",
    "default_probabilities = probabilities[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame({\"Id\": df_test_id, \"Probability\": default_probabilities})\n",
    "result[\"Id\"] = result[\"Id\"].astype(int)\n",
    "result[\"Probability\"] = result[\"Probability\"].astype(float)\n",
    "\n",
    "result.to_csv('model_output/predictions-best_model_RF.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/best_model_RF.pkl']"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(best_model, 'models/best_model_RF.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-08T01:47:47.468092Z",
     "iopub.status.idle": "2023-05-08T01:47:47.468570Z"
    }
   },
   "outputs": [],
   "source": [
    "model_KNN = KNeighborsClassifier()\n",
    "\n",
    "neighbors = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]\n",
    "param_grid = dict(n_neighbors=neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-08T01:47:47.469208Z",
     "iopub.status.idle": "2023-05-08T01:47:47.469911Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.932573 using {'n_neighbors': 8}\n",
      "Best: 0.932573 using {'n_neighbors': 8}\n"
     ]
    }
   ],
   "source": [
    "KNN_GridSearch = GridSearch(X_train,Y_train,model_KNN,param_grid)\n",
    "best_model, best_params = KNN_GridSearch.GridSearch()\n",
    "Prediction_KNN = KNN_GridSearch.BestModelPridict(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-08T01:47:47.470885Z",
     "iopub.status.idle": "2023-05-08T01:47:47.471335Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.97     95298\n",
      "           1       0.88      0.01      0.03      6916\n",
      "\n",
      "    accuracy                           0.93    102214\n",
      "   macro avg       0.90      0.51      0.50    102214\n",
      "weighted avg       0.93      0.93      0.90    102214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cp = classification_report(Y_train,Prediction_KNN)\n",
    "print(cp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.  , 0.  , 0.  , ..., 0.  , 0.25, 0.  ])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the best KNN model for prediction\n",
    "probabilities = best_model.predict_proba(X_test)\n",
    "\n",
    "# Extract the probability of belonging to the positive class (default)\n",
    "default_probabilities = probabilities[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame({\"Id\": df_test_id, \"Probability\": default_probabilities})\n",
    "result[\"Id\"] = result[\"Id\"].astype(int)\n",
    "result[\"Probability\"] = result[\"Probability\"].astype(float)\n",
    "\n",
    "result.to_csv('predictions-best_model_model_KNN.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-08T01:47:47.462344Z",
     "iopub.status.idle": "2023-05-08T01:47:47.462996Z"
    }
   },
   "outputs": [],
   "source": [
    "# model\n",
    "model = LogisticRegression()\n",
    "# Create regularization penalty space\n",
    "penalty = ['l1', 'l2']\n",
    "\n",
    "# Create regularization hyperparameter distribution using uniform distribution\n",
    "C = uniform(loc=0, scale=4)\n",
    "\n",
    "# Create hyperparameter options\n",
    "hyperparameters = dict(C=C, penalty=penalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-08T01:47:47.463751Z",
     "iopub.status.idle": "2023-05-08T01:47:47.464652Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tianhuihu/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "460 fits failed out of a total of 1000.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "460 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tianhuihu/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/tianhuihu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/tianhuihu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/tianhuihu/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan 0.93451974 0.93436319 0.934236   0.93439255 0.93438276\n",
      "        nan        nan        nan        nan 0.93466648 0.93433384\n",
      "        nan 0.93437298 0.93456865 0.93434363        nan        nan\n",
      " 0.93425559        nan 0.93434363 0.93450016        nan 0.93443167\n",
      "        nan 0.93433384 0.93428493 0.93462736 0.93455885 0.93424579\n",
      " 0.93429471        nan        nan 0.93444145        nan        nan\n",
      " 0.93440233 0.93449038        nan        nan 0.93450016 0.93458821\n",
      "        nan        nan        nan 0.93426537 0.93437298 0.93454907\n",
      "        nan 0.93440232        nan        nan 0.93422622        nan\n",
      " 0.93450016        nan        nan        nan        nan        nan\n",
      " 0.93432407        nan        nan        nan        nan 0.93437298\n",
      "        nan        nan 0.93449038 0.9344708         nan        nan\n",
      " 0.93436321 0.93440233        nan        nan 0.93452952 0.93447081\n",
      " 0.93431428 0.93449037 0.9343534         nan 0.93454908 0.93459799\n",
      " 0.9343632         nan 0.93448059        nan 0.93444146 0.93427515\n",
      " 0.93420666 0.93444147        nan 0.93432406        nan        nan\n",
      "        nan 0.93433385 0.93424579 0.93446103]\n",
      "  warnings.warn(\n",
      "/Users/tianhuihu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.934666 using {'C': 2.681870040713609, 'penalty': 'l2'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tianhuihu/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "460 fits failed out of a total of 1000.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "460 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tianhuihu/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/tianhuihu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/tianhuihu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/tianhuihu/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan 0.93451974 0.93436319 0.934236   0.93439255 0.93438276\n",
      "        nan        nan        nan        nan 0.93466648 0.93433384\n",
      "        nan 0.93437298 0.93456865 0.93434363        nan        nan\n",
      " 0.93425559        nan 0.93434363 0.93450016        nan 0.93443167\n",
      "        nan 0.93433384 0.93428493 0.93462736 0.93455885 0.93424579\n",
      " 0.93429471        nan        nan 0.93444145        nan        nan\n",
      " 0.93440233 0.93449038        nan        nan 0.93450016 0.93458821\n",
      "        nan        nan        nan 0.93426537 0.93437298 0.93454907\n",
      "        nan 0.93440232        nan        nan 0.93422622        nan\n",
      " 0.93450016        nan        nan        nan        nan        nan\n",
      " 0.93432407        nan        nan        nan        nan 0.93437298\n",
      "        nan        nan 0.93449038 0.9344708         nan        nan\n",
      " 0.93436321 0.93440233        nan        nan 0.93452952 0.93447081\n",
      " 0.93431428 0.93449037 0.9343534         nan 0.93454908 0.93459799\n",
      " 0.9343632         nan 0.93448059        nan 0.93444146 0.93427515\n",
      " 0.93420666 0.93444147        nan 0.93432406        nan        nan\n",
      "        nan 0.93433385 0.93424579 0.93446103]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.934666 using {'C': 2.681870040713609, 'penalty': 'l2'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tianhuihu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "LR_RandSearch = RandomSearch(X_train,Y_train,model,hyperparameters)\n",
    "LR_best_model,LR_best_params = LR_RandSearch.RandomSearch()\n",
    "Prediction_LR = LR_RandSearch.BestModelPridict(X_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-08T01:47:47.465278Z",
     "iopub.status.idle": "2023-05-08T01:47:47.466025Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97     95298\n",
      "           1       0.61      0.08      0.14      6916\n",
      "\n",
      "    accuracy                           0.93    102214\n",
      "   macro avg       0.77      0.54      0.56    102214\n",
      "weighted avg       0.92      0.93      0.91    102214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cp = classification_report(Y_train,Prediction_LR)\n",
    "print(cp)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the best LR model for prediction\n",
    "# 0.7923 private score 0.7899 public score\n",
    "probabilities = LR_best_model.predict_proba(X_test)\n",
    "\n",
    "# Extract the probability of belonging to the positive class (default)\n",
    "default_probabilities = probabilities[:, 1]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame({\"Id\": df_test_id, \"Probability\": default_probabilities})\n",
    "result[\"Id\"] = result[\"Id\"].astype(int)\n",
    "result[\"Probability\"] = result[\"Probability\"].astype(float)\n",
    "\n",
    "result.to_csv('predictions-best_model_LR.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-08T01:47:47.480824Z",
     "iopub.status.idle": "2023-05-08T01:47:47.481168Z"
    }
   },
   "outputs": [],
   "source": [
    "### ADABOOST CLASSIFIER ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-08T01:47:47.482109Z",
     "iopub.status.idle": "2023-05-08T01:47:47.482491Z"
    }
   },
   "outputs": [],
   "source": [
    "learning_rate_value = [.01,.05,.1,.5,1]\n",
    "n_estimators_value = [50,100,150,200,250,300]\n",
    "\n",
    "param_grid = dict(learning_rate=learning_rate_value, n_estimators=n_estimators_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-08T01:47:47.483179Z",
     "iopub.status.idle": "2023-05-08T01:47:47.483787Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.935723 using {'learning_rate': 0.05, 'n_estimators': 300}\n"
     ]
    }
   ],
   "source": [
    "model_Ad = AdaBoostClassifier()\n",
    "Ad_GridSearch = GridSearch(X_train,Y_train,model_Ad,param_grid)\n",
    "Prediction_Ad = Ad_GridSearch.BestModelPridict(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
