{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Give Me Some Credit\n",
    "![](https://www.freshfacs.com/v/vspfiles/photos/D3-2.jpg)\n",
    "Improve on the state of the art in credit scoring by predicting the probability that somebody will experience financial distress in the next two years.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Around 6% of samples defaulted\n",
    "- MonthlyIncome and NumberOfDependents have 29731 (19.82%) and 3924 (2.61%) null values respectively\n",
    "- We also notice that when NumberOfTimes90DaysLate has values above 17, there are 267 instances where the three columns \n",
    "- NumberOfTimes90DaysLate, NumberOfTime60-89DaysPastDueNotWorse, NumberOfTime30-59DaysPastDueNotWorse share the same values, specifically 96 and 98.\n",
    "    - We can see that sharing the same values of 96 and 98 respectively is not logical since trivial calculations can reveal that being 30 days past due for 96 times for a single person within a timespan of 2 years is not possible.\n",
    "- RevolvingUtilizationOfUnsecuredLines\n",
    "    - Defined as ratio of the total amount of money owed to total credit limit\n",
    "distribution of values is right-skewed, consider removing outliers\n",
    "    - It is expected that as this value increases, the proportion of people defaulting should increase as well\n",
    "    - However, we can see that as the minimum value of this column is set to 13, the proportion of defaulters is smaller than that belonging to the pool of clients with total amount of money owed not exceeding total credit limit.\n",
    "    - Thus we should remove those samples with RevolvingUtilizationOfUnsecuredLines's value more than equal to 13\n",
    "- age\n",
    "    - There seems to be more younger people defaulting and the distribution seems fine on the whole\n",
    "- NumberOfTimes90DaysLate\n",
    "    - It is interesting to note that there are no one who is 90 or more days past due between 17 and 96 times.\n",
    "- NumberOfTime60-89DaysPastDueNotWorse\n",
    "    - It is interesting to note that there are no one who is 60-89 days past due between 11 and 96 times.\n",
    "- NumberOfTime30-59DaysPastDueNotWorse\n",
    "    - It is interesting to note that there are no one who is 30-59 days past due between 13 and 96 times.\n",
    "- DebtRatio\n",
    "    - 2.5% of clients owe around 3490 or more times what they own\n",
    "    - For the people who have monthly income in this 2.5%, only 185 people have values for their monthly incomes and the values are either 0 or 1.\n",
    "    - There are 164 out of these 185 people who are of two different types, first with no monthly income and does not default and second with monthly income and does default.\n",
    "- MonthlyIncome\n",
    "    - Distribution of values is skewed, we can consider imputation with median.\n",
    "    - We can also consider imputing with normally distributed values with its mean and standard deviation.\n",
    "- Numberof Dependents\n",
    "    - We can consider imputing with its mode, which is zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "from IPython.display import HTML\n",
    "\n",
    "pd.set_option('max_columns', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score,precision_recall_curve,roc_curve\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, auc\n",
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-4442f5c5e3c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVotingClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlightgbm\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mlgb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, KFold\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "def evalBinaryClassifier(model, x, y, labels=['Positives','Negatives']):\n",
    "    '''\n",
    "    source: https://towardsdatascience.com/how-to-interpret-a-binary-logistic-regressor-with-scikit-learn-6d56c5783b49\n",
    "    Visualize the performance of  a Logistic Regression Binary Classifier.\n",
    "    \n",
    "    Displays a labelled Confusion Matrix, distributions of the predicted\n",
    "    probabilities for both classes, the ROC curve, and F1 score of a fitted\n",
    "    Binary Logistic Classifier. Author: gregcondit.com/articles/logr-charts\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model : fitted scikit-learn model with predict_proba & predict methods\n",
    "        and classes_ attribute. Typically LogisticRegression or \n",
    "        LogisticRegressionCV\n",
    "    \n",
    "    x : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
    "        Training vector, where n_samples is the number of samples\n",
    "        in the data to be tested, and n_features is the number of features\n",
    "    \n",
    "    y : array-like, shape (n_samples,)\n",
    "        Target vector relative to x.\n",
    "    \n",
    "    labels: list, optional\n",
    "        list of text labels for the two classes, with the positive label first\n",
    "        \n",
    "    Displays\n",
    "    ----------\n",
    "    3 Subplots\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    F1: float\n",
    "    '''\n",
    "    #model predicts probabilities of positive class\n",
    "    p = model.predict_proba(x)\n",
    "    if len(model.classes_)!=2:\n",
    "        raise ValueError('A binary class problem is required')\n",
    "    if model.classes_[1] == 1:\n",
    "        pos_p = p[:,1]\n",
    "    elif model.classes_[0] == 1:\n",
    "        pos_p = p[:,0]\n",
    "    \n",
    "    #FIGURE\n",
    "    plt.figure(figsize=[15,4])\n",
    "    \n",
    "    #1 -- Confusion matrix\n",
    "    cm = confusion_matrix(y,model.predict(x))\n",
    "    plt.subplot(131)\n",
    "    ax = sns.heatmap(cm, annot=True, cmap='Blues', cbar=False, \n",
    "                annot_kws={\"size\": 14}, fmt='g')\n",
    "    cmlabels = ['True Negatives', 'False Positives',\n",
    "              'False Negatives', 'True Positives']\n",
    "    for i,t in enumerate(ax.texts):\n",
    "        t.set_text(t.get_text() + \"\\n\" + cmlabels[i])\n",
    "    plt.title('Confusion Matrix', size=15)\n",
    "    plt.xlabel('Predicted Values', size=13)\n",
    "    plt.ylabel('True Values', size=13)\n",
    "      \n",
    "    #2 -- Distributions of Predicted Probabilities of both classes\n",
    "    df = pd.DataFrame({'probPos':pos_p, 'target': y})\n",
    "    plt.subplot(132)\n",
    "    plt.hist(df[df.target==1].probPos, density=True, bins=25,\n",
    "             alpha=.5, color='green',  label=labels[0])\n",
    "    plt.hist(df[df.target==0].probPos, density=True, bins=25,\n",
    "             alpha=.5, color='red', label=labels[1])\n",
    "    plt.axvline(.5, color='blue', linestyle='--', label='Boundary')\n",
    "    plt.xlim([0,1])\n",
    "    plt.title('Distributions of Predictions', size=15)\n",
    "    plt.xlabel('Positive Probability (predicted)', size=13)\n",
    "    plt.ylabel('Samples (normalized scale)', size=13)\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    \n",
    "    #3 -- ROC curve with annotated decision point\n",
    "    fp_rates, tp_rates, _ = roc_curve(y,p[:,1])\n",
    "    roc_auc = auc(fp_rates, tp_rates)\n",
    "    plt.subplot(133)\n",
    "    plt.plot(fp_rates, tp_rates, color='green',\n",
    "             lw=1, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], lw=1, linestyle='--', color='grey')\n",
    "    #plot current decision point:\n",
    "    tn, fp, fn, tp = [i for i in cm.ravel()]\n",
    "    plt.plot(fp/(fp+tn), tp/(tp+fn), 'bo', markersize=8, label='Decision Point')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate', size=13)\n",
    "    plt.ylabel('True Positive Rate', size=13)\n",
    "    plt.title('ROC Curve', size=15)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.subplots_adjust(wspace=.3)\n",
    "    plt.show()\n",
    "    #Print and Return the F1 score\n",
    "    tn, fp, fn, tp = [i for i in cm.ravel()]\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    F1 = 2*(precision * recall) / (precision + recall)\n",
    "    printout = (\n",
    "        f'Precision: {round(precision,2)} | '\n",
    "        f'Recall: {round(recall,2)} | '\n",
    "        f'F1 Score: {round(F1,2)} | '\n",
    "    )\n",
    "    print(printout)\n",
    "    return F1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File /kaggle/input/GiveMeSomeCredit/sampleEntry.csv does not exist: '/kaggle/input/GiveMeSomeCredit/sampleEntry.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File /kaggle/input/GiveMeSomeCredit/sampleEntry.csv does not exist: '/kaggle/input/GiveMeSomeCredit/sampleEntry.csv'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sampleEntry = pd.read_csv('sampleEntry.csv')\n",
    "train = pd.read_csv('/kaggle/input/GiveMeSomeCredit/cs-training.csv')\n",
    "test = pd.read_csv('/kaggle/input/GiveMeSomeCredit/cs-test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variable Name\tDescription\tType\n",
    "- ``SeriousDlqin2yrs``\tPerson experienced 90 days past due delinquency or worse\tY/N\n",
    "- ``RevolvingUtilizationOfUnsecuredLines``\tTotal balance on credit cards and personal lines of credit except real estate and no installment debt like car loans divided by the sum of credit limits\tpercentage\n",
    "- ``age``\tAge of borrower in years\tinteger\n",
    "- ``NumberOfTime3059DaysPastDueNotWorse``\tNumber of times borrower has been 30-59 days past due but no worse in the last 2 years.\tinteger\n",
    "- ``DebtRatio``\tMonthly debt payments, alimony,living costs divided by monthy gross income\tpercentage\n",
    "- ``MonthlyIncome``\tMonthly income\treal\n",
    "- ``NumberOfOpenCreditLinesAndLoans``\tNumber of Open loans (installment like car loan or mortgage) and Lines of credit (e.g. credit cards)\tinteger\n",
    "- ``NumberOfTimes90DaysLate``\tNumber of times borrower has been 90 days or more past due.\tinteger\n",
    "- ``NumberRealEstateLoansOrLines``\tNumber of mortgage and real estate loans including home equity lines of credit\tinteger\n",
    "- ``NumberOfTime60-89DaysPastDueNotWorse``\tNumber of times borrower has been 60-89 days past due but no worse in the last 2 years.\tinteger\n",
    "- ``NumberOfDependents``\tNumber of dependents in family excluding themselves (spouse, children etc.)\tinteger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('train shape  ',train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "train = train.dropna()\n",
    "train = train.drop(columns = ['Unnamed: 0'])\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Duplicate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "features = train.columns.values[0:30]\n",
    "unique_max_train = []\n",
    "unique_max_test = []\n",
    "for feature in features:\n",
    "    values = train[feature].value_counts()\n",
    "    unique_max_train.append([feature, values.max(), values.idxmax()])\n",
    "\n",
    "np.transpose((pd.DataFrame(unique_max_train, columns=['Feature', 'Max duplicates', 'Value'])).\\\n",
    "            sort_values(by = 'Max duplicates', ascending=False).head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Value Counts Target - SeriousDlqin2yrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "train.SeriousDlqin2yrs.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "train_X = train.drop([\"SeriousDlqin2yrs\"], axis=1)\n",
    "train_y = np.log1p(train[\"SeriousDlqin2yrs\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "from sklearn import ensemble\n",
    "model = ensemble.ExtraTreesRegressor(n_estimators=200, max_depth=20, max_features=0.5, n_jobs=-1, random_state=0)\n",
    "model.fit(train_X, train_y)\n",
    "\n",
    "## plotando as importâncias ##\n",
    "feat_names = train_X.columns.values\n",
    "importances = model.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in model.estimators_], axis=0)\n",
    "indices = np.argsort(importances)[::-1][:20]\n",
    "\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(len(indices)), importances[indices], color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(len(indices)), feat_names[indices], rotation='vertical')\n",
    "plt.xlim([-1, len(indices)])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "def plot_new_feature_distribution(df1, df2, label1, label2, features, n):\n",
    "    i = 0\n",
    "    sns.set_style('whitegrid')\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots(2,n,figsize=(18,8))\n",
    "\n",
    "    for feature in features:\n",
    "        i += 1\n",
    "        plt.subplot(2,n,i)\n",
    "        sns.kdeplot(df1[feature], bw=0.5,label=label1)\n",
    "        sns.kdeplot(df2[feature], bw=0.5,label=label2)\n",
    "        plt.xlabel(feature, fontsize=11)\n",
    "        locs, labels = plt.xticks()\n",
    "        plt.tick_params(axis='x', which='major', labelsize=8)\n",
    "        plt.tick_params(axis='y', which='major', labelsize=8)\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc(y_test,prob):\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, probs)\n",
    "    # plot no skill\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "    # plot the roc curve for the model\n",
    "    plt.plot(fpr, tpr, marker='.')\n",
    "    plt.title(\"ROC curve\")\n",
    "    plt.xlabel('false positive rate')\n",
    "    plt.ylabel('true positive rate')\n",
    "    # show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic(X,y):\n",
    "    y_train=train['SeriousDlqin2yrs'].astype('uint8')\n",
    "    X_train,X_test,y_train,y_test=train_test_split(train.drop('SeriousDlqin2yrs',axis=1),y_train,test_size=.2,random_state=2020)\n",
    "    lr=LogisticRegression()\n",
    "    lr.fit(X_train,y_train)\n",
    "    prob=lr.predict_proba(X_test)\n",
    "    \n",
    "    roc=roc_auc_score(y_test, lr.predict_proba(X_test)[:,1])\n",
    "    print('roc ',roc)\n",
    "\n",
    "    return (prob[:,1],y_test)\n",
    "y_train=train['SeriousDlqin2yrs'].astype('uint8')\n",
    "probs,y_test=logistic(train.drop('SeriousDlqin2yrs',axis=1),y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc(y_test,probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_x, val_x, train_y, val_y=train_test_split(train.drop('SeriousDlqin2yrs',axis=1),y_train,test_size=.2,random_state=2020)\n",
    "\n",
    "clf = LogisticRegression(solver=\"lbfgs\").fit(train_x, train_y)\n",
    "pred_y = clf.predict(val_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rocrl=roc_auc_score(val_y, pred_y)\n",
    "rocrl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc(val_y, pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model = RandomForestClassifier(n_estimators=220).fit(train_x,train_y)\n",
    "predictionforest = model.predict(val_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "rocrf=roc_auc_score(val_y, predictionforest)\n",
    "print('roc ',rocrf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc(val_y, predictionforest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_cfl = xgb.XGBClassifier(n_jobs = -1, \n",
    "                            n_estimators = 220)\n",
    "\n",
    "xgb_cfl.fit(train_x, train_y)\n",
    "y_scorexgb = xgb_cfl.predict_proba(val_x)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rocxgb=roc_auc_score(val_y, y_scorexgb)\n",
    "print('roc ',rocxgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc(val_y, y_scorexgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search CV "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### XGB Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_cfl = xgb.XGBClassifier(n_jobs = -1)\n",
    "xgb_cfl.fit(train_x, train_y)\n",
    "y_pred = xgb_cfl.predict(val_x)\n",
    "y_score = xgb_cfl.predict_proba(val_x)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "param_grid = {\n",
    "            'n_estimators': [50, 100, 200]\n",
    "              }\n",
    "\n",
    "CV_xgb_cfl = GridSearchCV(estimator = xgb_cfl, param_grid = param_grid, scoring ='roc_auc', verbose = 2)\n",
    "CV_xgb_cfl.fit(train_x, train_y)\n",
    "\n",
    "best_parameters = CV_xgb_cfl.best_params_\n",
    "print(\"The best parameters: \", best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_cfl2 = xgb.XGBClassifier(n_jobs = -1, \n",
    "                            n_estimators = 120)\n",
    "\n",
    "xgb_cfl2.fit(train_x, train_y)\n",
    "y_score2 = xgb_cfl2.predict_proba(val_x)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rocxgb=roc_auc_score(val_y, y_score2)\n",
    "print('roc ',rocxgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc(val_y, y_score2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Score Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F1 = evalBinaryClassifier(xgb_cfl2, val_x, val_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probability Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "## Target 1\n",
    "target1 = pd.DataFrame({\"Target\": val_y, 'Probability': y_score2 })\n",
    "print(target1.loc[target1.Target == 1, 'Probability'].describe())\n",
    "target1.loc[target1.Target == 1, 'Probability'].hist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=test.drop([\"SeriousDlqin2yrs\",\"Unnamed: 0\"],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = xgb_cfl2.predict_proba(test)[:,1]\n",
    "sampleEntry[\"Probability\"]=res\n",
    "sampleEntry.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleEntry.to_csv(\"submission.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy model using mia marketplace\n",
    "![](https://miro.medium.com/max/1773/1*QuP5nFnvBNg-IrHvQ2-hCA.png)\n",
    "mia is a platform for building and sharing machine learning apps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mia Platform link, **Risk Models**: https://miamarketplace.com/pages/riskmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from platform import python_version\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model to file\n",
    "xgb_cfl2.save_model(\"model.bst\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
